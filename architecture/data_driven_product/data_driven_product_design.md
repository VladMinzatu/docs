#### Speed matters here
Serving has to be fast, so do the miniumum amount of work possible on each request. Push work to off-line as much as possible, as long as the latency for computing the result is acceptable.

#### Keep serving flexible
Serving should be flexible enough to apply arbitrary logic so abstractions for very flexible models are necessary to allow for algorithmic innovation. This is why the model services are separated from the API Gateway and they should be minimally constrained (maybe have a fixed API, but implementation language/framework should not be constrained).

#### Keep the gateway service simple
Because you want to have very good visibility into the quality of what you are providing to your customers (see above), you should keep things simple and avoid an overload of concepts in the gateway service. You'll probably need the concept of a **context** if your service has multiple stakeholders. And an internal concept of a **model** to iterate on. Try to keep it at that!

If you need to also support business rules, you may want to make this configurable per context, but make sure you only reserve that capability for hard and fixed requirements. For example, if you're recommending videos to a user, you may have a strict requirement (in some contexts) to not recommend videos  if the user has already seen them. This is a concern that can be implemented as a business rule on top of all models. You will then have to monitor what effect this business rule has on the performance of the model: does it often leave you with no recommendations at serving time? Then the model may need to be tweaked to play better with this non-negociable rule. 

However, what you don't want is to abuse the business rule capability for tweaks that can improve the model's performance (e.g. querying some other data source at run-time and re-ranking results). It may be tempting to do so, because it is very easy and conventient to implement, but don't underestimate the cost of then monitoring the impact of this business rule on different models. It is pointless to build capabilities to configure and tweak models if you don't run AB tests to then optimize the configurations in different contexts. But that takes a long time, so it's best to make a deliberate decision to try and incorporate new signals into your models and follow the typical workflow of validating offline and doing AB testing. This is why it's important to restrict the business rules capabilities on top of models to the non-negotiable rules: because it removes the need to test and tweak the interaction between models and business rules - instead, you just test and compare models. 

So essentially, the domain would have two entities: a **context** and a **model** (because the business rules are part of the context). The context has associated business rules and the model has an associated prediction logic. AB tests then compare different models in a given context. Ideally, models and contexts are immutable in their configurations, but if mutation is allowed, it should only be possible to do that when there are no AB tests running involving said model and context.

Again, keep configuration to a minimum, because it makes it very hard to keep track of quality metrics. For example, instead of implementing dynamic filtering capabilities, prefer creating separate contexts for which you get monitoring out of the box. The filtering will still need to be done, but push things back from the serving, for improvements in both performance and clarity.

Beyond pairing contexts and models, the gateway can include capabilities of combining different moels in hierarchies and configuring how to communicate the outcome of the serving to the user. But the main point is: you want very good clarity into what is going on at this level, so the fewer concepts, the better. 
